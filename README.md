# DeepLearning4UTI
The aim of this repository is to create a comprehensive, curated list of resources which can be used for ultrasound tongue image (UTI) analysis, especially for the deep learning-based approaches.

## Contents

* [Scientific Paper](#scientific-papers)
* [Code](#other-resources)
* [Related Labs](#related-lists)
* [Contributing](#contributing)
* [License](#license)

## Scientific Papers
#### Motion Tracking

* [Extraction and tracking of the tongue surface from ultrasound image sequences.](https://ieeexplore.ieee.org/abstract/document/698623) Akgul, Yusuf Sinan, Chandra Kambhamettu, and Maureen Stone. (1998) IEEE Computer Society Conference on Computer Vision and Pattern Recognition.
* [Automatic extraction and tracking of the tongue contours.](https://ieeexplore.ieee.org/abstract/document/811315) Akgul, Yusuf Sinan, Chandra Kambhamettu, and Maureen Stone. (1999) IEEE Transactions on Medical Imaging.
* [A guide to analysing tongue motion from ultrasound images.](https://www.dental.umaryland.edu/media/sod/vocal-tract-visualization-laboratory/Guide_to_Ultrasound.pdf) Stone, Maureen. (2005) Clinical linguistics & phonetics.
* [Automatic contour tracking in ultrasound images.](https://pdfs.semanticscholar.org/3f1a/2e2ccc5774a60b527ac6f5a7d0665b25895b.pdf) Li, Min, Chandra Kambhamettu, and Maureen Stone (2005) Clinical linguistics & phonetics.
* [Deep belief networks for real-time extraction of tongue contours from ultrasound during speech.](http://www.u.arizona.edu/~jjberry/ICPR.pdf) Fasel, Ian, and Jeff Berry. (2010) 20th International Conference on Pattern Recognition. IEEE.
* [Tongue contour extraction from ultrasound images based on deep neural network.](https://arxiv.org/ftp/arxiv/papers/1605/1605.05912.pdf) Jaumard-Hakoun, Aurore, et al. (2016) ICPhS.
* [A comparative study on the contour tracking algorithms in ultrasound tongue images with automatic re-initialization.](https://asa.scitation.org/doi/full/10.1121/1.4951024?TRACK=RSS) Xu, Kele, et al. (2016) The Journal of the Acoustical Society of America Express Letters.
* [Robust contour tracking in ultrasound tongue image sequences.](https://www.tandfonline.com/doi/abs/10.3109/02699206.2015.1110714) Xu, Kele, et al. (2016) Clinical linguistics & phonetics.
* [BowNet: Dilated Convolution Neural Network for Ultrasound Tongue Contour Extraction.](https://arxiv.org/abs/1906.04232) Mozaffari, M. Hamed, and Won-Sook Lee (2019)
* [Transfer Learning for Ultrasound Tongue Contour Extraction with Different Domains.](https://arxiv.org/abs/1906.04301) Mozaffari, M. Hamed, and Won-Sook Lee (2019)

#### 3D Tongue Motion Visualization Using Ultrasound


#### Ultrasound-Based Silent Speech Interface
* [Speech synthesis from real time ultrasound images of the tongue.](https://www.researchgate.net/profile/Bruce_Denby/publication/224750547_Speech_synthesis_from_real_time_ultrasound_images_of_the_tongue/links/02bfe50cb7a0772b6a000000/Speech-synthesis-from-real-time-ultrasound-images-of-the-tongue.pdf) Bruce Denby and Maureen Stone (2004)  IEEE International Conference on Acoustics, Speech, and Signal Processing.
* [Development of a silent speech interface driven by ultrasound and optical images of the tongue and lips.](https://www.neurones.espci.fr/Articles_PS/SPEECHCOM%202.pdf) Hueber, Thomas, et al. (2010) Speech Communication
* [UTowards a Practical Silent Speech Interface Based on Vocal Tract Imaging](http://www.gipsa-lab.grenoble-inp.fr/~thomas.hueber/mes_documents/Denby_et_al_ISSP_2011_Montreal.pdf) Denby, Bruce, et al. (2011) Speech Communication
* [Updating the silent speech challenge benchmark with deep learning](https://arxiv.org/abs/1709.06818) Ji, Yan, et al. (2018) Speech Communication.
* [Ultrasound-based Silent Speech Interface Built on a Continuous Vocoder.](https://arxiv.org/abs/1906.09885) Csap√≥, T. G. et al. (2019) 

#### Tutorials


## Code

* [Predicting tongue motion in unlabeled ultrasound videos using convolutional LSTM neural network](https://github.com/shuiliwanwu/ConvLstm-ultrasound-videos) -  Chaojie Zhao, Peng Zhang, Jian Zhu, Chengrui Wu, Huaimin Wang, Kele Xu. ICASSP 2019.

* [Synchronising audio and ultrasound by learning cross-modal embeddings](https://github.com/aeshky/ultrasync) - Eshky, Aciel, et al. arXiv preprint arXiv:1907.00758.

## Data

## Related Labs
* [Vocal Tract Visualization Laboratory, University of Maryland, Baltimore, USA](https://www.dental.umaryland.edu/speech/) 
* [Haskins Laboratories, Yale University, New Haven, USA](http://www.haskins.yale.edu/understandingspeech.html) 
* [Speech Disorders & Technology Lab, UT Dallas, USA](https://www.utdallas.edu/wanglab/) 
* [School of Electrical Engineering and Computer Science, University of Ottawa, Canada](http://www.site.uottawa.ca/~wslee/index.shtml) 
* [Laboratoire Signaux, Mod les, Apprentissage statistique (SIGMA), Paris, France](https://www.neurones.espci.fr/index_E.htm)
* [The Langevin Institute, Paris, France](https://www.institut-langevin.espci.fr/the_langevin_institute?lang=en)
* [GIPSA-lab, Grenoble, France](http://www.gipsa-lab.grenoble-inp.fr/en/home.php)
* [Centre for Speech Technology Research, University of Edinburgh, UK](http://www.cstr.ed.ac.uk/)
* [Psychological Sciences and Health, University of Strathclyde, UK](https://www.strath.ac.uk/humanities/psychologicalscienceshealth/)
* [Clinical Audiology, Speech and Language Research Centre, Queen Margaret University, UK](https://www.qmu.ac.uk/research-and-knowledge-exchange/research-centres-institutes-and-groups/clinical-audiology-speech-and-language-research-centre/)
* [Articulate Instruments Ltd., UK](www.articulateinstruments.com/)
* [Speech Technology and Smart Interactions Laboratory, Budapest University of Technology and Economics, Hungary](http://smartlab.tmit.bme.hu/index-en)
* [The Key Laboratory of Cognitive Computing and Applications, Tianjin University, China](http://cs.tju.edu.cn/csweben/researchdetail?item=KLCCA)


## Contributing

Your contributions are always welcome! Please take a look at the [contribution guidelines](CONTRIBUTING.md) first.
Please feel free to pull requests, email Kele Xu (kelele.xu@gmail.com) or join our chats to add links.
I will keep some pull requests open if I'm not sure whether those libraries are awesome, you could vote for them by adding üëç to them.

## License

[![License: CC BY 4.0](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)
