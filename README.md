# DeepLearning4UTI
The aim of this repository is to create a comprehensive, curated list of resources which can be used for ultrasound tongue image (UTI) analysis, especially for the deep learning-based approaches.

## Contents

* [Scientific Paper](#scientific-papers)
* [Code](#other-resources)
* [Related Labs](#related-lists)
* [Contributing](#contributing)
* [License](#license)

## Scientific Papers
#### Motion Tracking
* [Jaumard-Hakoun, A., Xu, K., Roussel-Ragot, P., Dreyfus, G., & Denby, B. (2016). Tongue contour extraction from ultrasound images based on deep neural network. arXiv preprint arXiv:1605.05912.](https://arxiv.org/ftp/arxiv/papers/1605/1605.05912.pdf) - John C. Glover, Victor Lazzarini and Joseph Timoney, Linux Audio Conference 2011.
#### Other Analysis

## Code

* [Predicting tongue motion in unlabeled ultrasound videos using convolutional LSTM neural network](https://github.com/shuiliwanwu/ConvLstm-ultrasound-videos) -  Chaojie Zhao, Peng Zhang, Jian Zhu, Chengrui Wu, Huaimin Wang, Kele Xu. ICASSP 2019.

## Related Labs
* [Vocal Tract Visualization Laboratory, University of Maryland, Baltimore, USA](https://www.dental.umaryland.edu/speech/) 
* [Haskins Laboratories, Yale University, New Haven, USA](http://www.haskins.yale.edu/understandingspeech.html) 
* [Speech Disorders & Technology Lab, UT Dallas, USA](https://www.utdallas.edu/wanglab/) 
* [School of Electrical Engineering and Computer Science, University of Ottawa, Canada](http://www.site.uottawa.ca/~wslee/index.shtml) 
* [Laboratoire Signaux, Mod les, Apprentissage statistique (SIGMA), Paris, France](https://www.neurones.espci.fr/index_E.htm)
* [The Langevin Institute, Paris, France](https://www.institut-langevin.espci.fr/the_langevin_institute?lang=en)
* [GIPSA-lab, Grenoble, France](http://www.gipsa-lab.grenoble-inp.fr/en/home.php)
* [Centre for Speech Technology Research, University of Edinburgh, UK](http://www.cstr.ed.ac.uk/)
* [Psychological Sciences and Health, University of Strathclyde, UK](https://www.strath.ac.uk/humanities/psychologicalscienceshealth/)
* [Clinical Audiology, Speech and Language Research Centre, Queen Margaret University, UK](https://www.qmu.ac.uk/research-and-knowledge-exchange/research-centres-institutes-and-groups/clinical-audiology-speech-and-language-research-centre/)
* [Articulate Instruments Ltd., UK](www.articulateinstruments.com/)
* [Speech Technology and Smart Interactions Laboratory, Budapest University of Technology and Economics, Hungary](http://smartlab.tmit.bme.hu/index-en)
* [The Key Laboratory of Cognitive Computing and Applications, Tianjin University, China](http://cs.tju.edu.cn/csweben/researchdetail?item=KLCCA)


## Contributing

Your contributions are always welcome! Please take a look at the [contribution guidelines](CONTRIBUTING.md) first.

I will keep some pull requests open if I'm not sure whether those libraries are awesome, you could vote for them by adding üëç to them.

## License

[![License: CC BY 4.0](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)
